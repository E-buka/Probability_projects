{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c1313c-30e2-4a8b-9db6-d7f788a6af7e",
   "metadata": {},
   "source": [
    "### Classification for spam messages\n",
    "Using Naive Bayes algorithm to classify messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4245d222-cf29-4161-b94c-1c549a3b3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e18db1-8c26-4c2a-b50a-897432ff2163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f67775-b8ae-4601-9269-e017098a19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efd3035-e426-4871-b94a-31dee1c06c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('Label', normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d520c095-f097-4e65-9653-2c49b464a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Spliting the dataset into train (80%) and test (20%) dataset by randomizing and sampling. \n",
    "# About 80% of the dataset is 4458 while 1114 messages accounts for 20% roughly. \n",
    "\n",
    "randomized = df.sample( frac=1, random_state=1, ignore_index=False)\n",
    "train_set = round(len(randomized)*0.8)\n",
    "\n",
    "train_data = randomized[:train_set].reset_index(drop=True)\n",
    "test_data = randomized[train_set:].reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd810411-9efe-4fa5-b91b-d4233e82f5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.value_counts('Label', normalize=True)*100)\n",
    "print(test_data.value_counts('Label', normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba67b28-ba60-4085-8cc6-5636b1c3c396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes, princess. are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth.. there's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep, by the pretty sculpture\n",
       "1   ham      yes, princess. are you going to make me moan?\n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent.\n",
       "4   ham  i forgot 2 ask ü all smth.. there's a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing punctuations from the SMS text\n",
    "train_data['SMS'] = train_data['SMS'].str.replace(r'\\W', ' ').str.lower()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102fa614-91d9-4fee-b423-20002592644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69633\n",
      "11860\n"
     ]
    }
   ],
   "source": [
    "# Extracting all the vocabulary in the SMS text\n",
    "vocabulary = []\n",
    "count = 0\n",
    "for sms in train_data['SMS'].str.split():\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05426418-d9cb-4c47-a3e7-13b89dac1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, word in enumerate(vocabulary):\n",
    "    if word == '':\n",
    "        print(index, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393dbce6-488c-40a6-bf2d-afa64dc3d710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build</th>\n",
       "      <th>pobox12n146tf150p</th>\n",
       "      <th>cash!</th>\n",
       "      <th>told</th>\n",
       "      <th>saturday,</th>\n",
       "      <th>simply</th>\n",
       "      <th>really.</th>\n",
       "      <th>woke</th>\n",
       "      <th>ovulate.when</th>\n",
       "      <th>post,</th>\n",
       "      <th>...</th>\n",
       "      <th>\"margaret</th>\n",
       "      <th>arithmetic</th>\n",
       "      <th>ahhhh...just</th>\n",
       "      <th>clothes,</th>\n",
       "      <th>join...</th>\n",
       "      <th>dem!!!</th>\n",
       "      <th>4u</th>\n",
       "      <th>haunt</th>\n",
       "      <th>lect</th>\n",
       "      <th>atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 11860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   build  pobox12n146tf150p  cash!  told  saturday,  simply  really.  woke  \\\n",
       "0      0                  0      0     0          0       0        0     0   \n",
       "1      0                  0      0     0          0       0        0     0   \n",
       "2      0                  0      0     0          0       0        0     0   \n",
       "\n",
       "   ovulate.when  post,  ...  \"margaret  arithmetic  ahhhh...just  clothes,  \\\n",
       "0             0      0  ...          0           0             0         0   \n",
       "1             0      0  ...          0           0             0         0   \n",
       "2             0      0  ...          0           0             0         0   \n",
       "\n",
       "   join...  dem!!!  4u  haunt  lect  atten  \n",
       "0        0       0   0      0     0      0  \n",
       "1        0       0   0      0     0      0  \n",
       "2        0       0   0      0     0      0  \n",
       "\n",
       "[3 rows x 11860 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming all the words in vocabulary into dictionary and then dataframe\n",
    "word_count = {word: [0] * len(train_data['SMS']) for word in vocabulary}\n",
    "count = 0\n",
    "for index, sms in enumerate(train_data['SMS']):\n",
    "    sms = sms.split()\n",
    "    for text in sms:\n",
    "        word_count[text][index] += 1\n",
    "\n",
    "word_count_per_sms = pd.DataFrame(word_count)\n",
    "word_count_per_sms.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d66b307-8214-4f19-a5af-16f2aa2fb5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to\n",
       "0    3095\n",
       "1    1038\n",
       "2     247\n",
       "3      53\n",
       "4      17\n",
       "5       5\n",
       "7       1\n",
       "8       1\n",
       "6       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_per_sms['to'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f29d590-454a-4e22-ae0a-02c1bb716136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>build</th>\n",
       "      <th>pobox12n146tf150p</th>\n",
       "      <th>cash!</th>\n",
       "      <th>told</th>\n",
       "      <th>saturday,</th>\n",
       "      <th>simply</th>\n",
       "      <th>really.</th>\n",
       "      <th>woke</th>\n",
       "      <th>...</th>\n",
       "      <th>\"margaret</th>\n",
       "      <th>arithmetic</th>\n",
       "      <th>ahhhh...just</th>\n",
       "      <th>clothes,</th>\n",
       "      <th>join...</th>\n",
       "      <th>dem!!!</th>\n",
       "      <th>4u</th>\n",
       "      <th>haunt</th>\n",
       "      <th>lect</th>\n",
       "      <th>atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep, by the pretty sculpture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes, princess. are you going to make me moan?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 11862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            SMS  build  \\\n",
       "0   ham                   yep, by the pretty sculpture      0   \n",
       "1   ham  yes, princess. are you going to make me moan?      0   \n",
       "2   ham                     welp apparently he retired      0   \n",
       "\n",
       "   pobox12n146tf150p  cash!  told  saturday,  simply  really.  woke  ...  \\\n",
       "0                  0      0     0          0       0        0     0  ...   \n",
       "1                  0      0     0          0       0        0     0  ...   \n",
       "2                  0      0     0          0       0        0     0  ...   \n",
       "\n",
       "   \"margaret  arithmetic  ahhhh...just  clothes,  join...  dem!!!  4u  haunt  \\\n",
       "0          0           0             0         0        0       0   0      0   \n",
       "1          0           0             0         0        0       0   0      0   \n",
       "2          0           0             0         0        0       0   0      0   \n",
       "\n",
       "   lect  atten  \n",
       "0     0      0  \n",
       "1     0      0  \n",
       "2     0      0  \n",
       "\n",
       "[3 rows x 11862 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating both word_count_per_sms and train_set dataframes\n",
    "train_set_complete = pd.concat([train_data, word_count_per_sms], axis=1)\n",
    "train_set_complete.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef6f46c-327d-4070-bd85-ca886bab9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254\n",
      "0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "## Calculating Constants, probability shall be represented with p, ham represents non_spam sms\n",
    "## p(spam), p(ham), total words in spam sms, total words in non_spam and total vocabulary\n",
    "\n",
    "### p(spam) and p(ham)\n",
    "spam_sms = train_set_complete.loc[train_set_complete['Label'] == 'spam']\n",
    "total_spam_sms = len(spam_sms)\n",
    "total_non_spam_sms = len(train_set_complete) - total_spam_sms\n",
    "p_spam = total_spam_sms / len(train_set_complete)\n",
    "p_ham = total_non_spam_sms / len(train_set_complete)\n",
    "print(p_spam)\n",
    "print(p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98563cc6-a4fb-49c4-8198-48f6cb9588f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55376 14257\n"
     ]
    }
   ],
   "source": [
    "## N_spam, N_ham, N_vocabulary, alpha is Laplace smoothing parameter for Naive Bayes\n",
    "alpha = 1 \n",
    "n_spam = 0\n",
    "n_ham = 0\n",
    "\n",
    "for sms in spam_sms['SMS'].str.split():\n",
    "    n_spam += len(sms)\n",
    "\n",
    "ham_sms = train_set_complete.loc[train_set_complete['Label'] == 'ham']\n",
    "\n",
    "for sms in ham_sms['SMS'].str.split():\n",
    "    n_ham += len(sms)\n",
    "\n",
    "n_vocabulary = len(vocabulary)\n",
    "      \n",
    "print(n_ham, n_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a0276c7-ac0a-485a-9d5f-8eb8cfa3ba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654104979811574"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048b5234-a0cc-405d-9b6e-4110695788c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating parameters \n",
    "ham_parameter = {word:0 for word in vocabulary}\n",
    "spam_parameter = {word : 0 for word in vocabulary}\n",
    "\n",
    "for word in vocabulary: \n",
    "    word_given_spam = spam_sms[word].sum()\n",
    "    prob_word_given_spam = (word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    spam_parameter[word] = prob_word_given_spam\n",
    "    \n",
    "    word_given_ham = ham_sms[word].sum()\n",
    "    prob_word_given_ham = (word_given_ham + alpha)/ (n_ham + alpha  * n_vocabulary)\n",
    "    ham_parameter[word] = prob_word_given_ham\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "012274e7-0ccf-49fe-8db7-619726f8259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifying new messages \n",
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    " \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in spam_parameter: \n",
    "            p_spam_given_message *= spam_parameter[word]\n",
    "        if word in ham_parameter:\n",
    "            p_ham_given_message *= ham_parameter[word]\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662472db-9c80-4071-bf1e-9237761b6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.1680023632078457e-26\n",
      "P(Ham|message): 6.088544142463393e-28\n",
      "Label: Spam\n",
      "P(Spam|message): 2.234299283967944e-26\n",
      "P(Ham|message): 8.376346103813855e-22\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "word1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "word2 = 'Sounds good, Tom, then see u there'\n",
    "\n",
    "classify(word1)\n",
    "classify(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15f3e2ec-e7da-459b-b0c9-d2d4bf3a8b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...       ham\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## measuring spam filter's accuracy \n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    " \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in spam_parameter: \n",
    "            p_spam_given_message *= spam_parameter[word]\n",
    "        if word in ham_parameter:\n",
    "            p_ham_given_message *= ham_parameter[word]\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'\n",
    "\n",
    "test_data['predicted'] = train_data['SMS'].apply(classify_test_set)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0f0f120-01b8-41a0-af3d-ed9cb2763536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692998204667864\n"
     ]
    }
   ],
   "source": [
    "## Measuring the accuracy\n",
    "correct = 0 \n",
    "total = test_data.shape[0]\n",
    "for row in test_data.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct/total \n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e04a9-a622-4b9c-abe0-9025ee4d01e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
